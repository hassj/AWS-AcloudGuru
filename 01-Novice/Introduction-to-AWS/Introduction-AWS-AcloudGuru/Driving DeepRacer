Hello, Cloud Gurus and welcome to Driving DeepRacer. In this lesson,
we're going to learn all about AWS DeepRacer. So let's get started.
AWS DeepRacer is a self-driving car that AWS have created
to teach you reinforcement learning,
which is an advanced machine learning technique.
It's a fun way to get started with machine learning.
There's loads of tutorials to help you with the basics and you get to test them
in an exciting way, on a racetrack.
Let's take a closer look at the car.
It's a 1/18 scale car with a camera, and a small Intel computer,
and a bunch of sensors strapped to it,
and it can be trained to drive around a track using vision and computing
power. We do this by use of something called a model.
Think of the model as a brain. First, we need to train the brain, how to drive,
then we load the brain into the car to create a model. We need a computer.
In this case, the AWS, the price of service is our computer,
and we need some data and we need a way to analyze the data,
a set of instructions, and we call that an algorithm.
If you've ever programmed before. You know,
an algorithm is just a list of instructions written in a programming language.
In DeepRacer's case the algorithm is called a reward function.
This reward function is given a whole bunch of data from the car.
These are called parameters, and this is actually the list of parameters,
which we have access to when programming DeepRacer.
You can see we're given information such as if all four wheels are on the track.
Its current coordinates in an X and Y position.
Its distance from the center of the track. If it is crashed and so on,
and it's your job to use these to program this reward function,
to make the car drive.
But the reward function only has one output or result after you run it,
and that result is a number that you calculate.
So you're basically taking all of the input data from the car,
doing some mathematics on it, and then producing a result.
The DeepRacer machine learning service then runs this reward function over and
over again, trying to figure out the best way to get around the track.
But how on earth does just an algorithm returning one result of a mathematics
calculation, make the car drive and how can you train it to drive?
The clue is in the name. It's a reward function.
What you need to do is write your algorithm to reward or
calculate a higher value when the car does something correctly.
So you aren't training a car to drive.
You're rewarding a car for driving correctly,
and that's the key to programming DeepRacer using reinforcement learning
and machine learning. I'll show you this very simple example,
reward function that can actually be trained to drive a DeepRacer car fairly
well, and it's AWS' first example in their documentation.
This reward function tries to get the car,
to follow the center line of a race track and it rewards it more based on how
close it is to the middle of the track. Firstly,
it gets the track width and the distance from the center of the track from the
parameters.
It then calculates 3 markers that are increasingly further away from the center
of the track,
and then it gives a higher reward the closer you are to the center
line, and a lower reward the further away you are,
and then it returns the reward.
Its aim is to keep the car in the middle of the track and that's it.
It's a really simple algorithm and it works okay,
but it's not going to win you any DeepRacer championships. Oh,
did I mention there are championships where you get to race against other
DeepRacer around the world?
I'll leave a link in the description of this lesson for you to check them out.
If you'd like to learn more about the DeepRacer,
I'll also leave a link to a series on the A Cloud Guru platform that my
colleague Scott Pletcher and I made,
where you can learn every single thing you ever wanted to know about the
DeepRacer. All right. Thanks for watching. If you have any questions,
please let me know. Otherwise feel free to move on to the next lesson.